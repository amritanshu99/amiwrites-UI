ğŸ§  1. Why RL Instead of Just Counting?

If you just count clicks â†’ old blogs always dominate.

If you just count impressions â†’ noisy and unfair.

RL solves this: balance explore vs exploit.

ğŸ‘‰ Exploit = keep showing blogs with proven high CTR.
ğŸ‘‰ Explore = still test less-known blogs to see if they can surprise.

This is exactly what your Thompson Sampling does.

ğŸ“¦ 2. Data Model: BlogStat

Each blog has a stat row in MongoDB (BlogStat.js):

{
  postId: ObjectId,         // link to Blog
  alpha: 8.14,              // engaged reads (successes)
  beta: 33.31,              // unengaged reads (failures)
  impressions: 127.05,      // times blog was shown
  clicks: 23.54,            // times user clicked from list
  engaged_count: 6.85,      // engaged reads count
  words: 606,               // blog length (for read time calc)
  category: null,
  publishedAt: 2025-08-23,  // when blog published
  lastUpdated: 2025-09-02,  // last event processed
}


ğŸ’¡ Key Idea:

alpha & beta = the â€œbrainâ€ â†’ belief about quality.

impressions/clicks = support metrics for CTR monitoring.

engaged_count = debugging/analytics.

words = used to compute expected reading time.

âš¡ 3. API Lifecycle
(a) Impression API (/events/impression)

ğŸ“ When called:

On blog detail page load (first render).

ğŸ“ What happens in DB:

$inc: { impressions: 1 }


ğŸ“ Meaning:

"This blog was seen once."

No reward signal yet (user may bounce).

(b) Click API (/events/click)

ğŸ“ When called:

When user clicks a blog from list/grid view.

ğŸ“ What happens in DB:

$inc: { clicks: 1 }


ğŸ“ Meaning:

"User chose this blog over others."

Still no Î±/Î² change (that happens only at read-end).

(c) Read-End API (/events/read-end)

ğŸ“ When called:

On scroll/unload/visibilitychange after user opened blog.

Also snapshot at 10s even if user doesnâ€™t leave.

ğŸ“ What happens:

Compute expected dwell time:

expected_ms = words / 200 * 60 * 1000


606 words â†’ ~3 min expected.

Compute actual dwell ratio:

ratio = dwell_ms / expected_ms


If dwell â‰¥ 60% expected OR scroll â‰¥ 70% â†’ engaged = true.

Update BlogStat:

if engaged:
  alpha += 1
  engaged_count += 1
else:
  beta += 1


lastUpdated set to now.

ğŸ“ Meaning:

This is the reward feedback.

Every read is either a success (alpha) or failure (beta).

This directly trains RL.

ğŸ² 4. Thompson Sampling (The Brain)

In /trending API:

theta = betaSample(alpha, beta)
score = theta * freshBoost * jitter


betaSample(Î±, Î²) = draw random value from Beta distribution.

Blogs with high Î±/low Î² â†’ Î¸ drawn close to 1.

Blogs with low Î±/high Î² â†’ Î¸ drawn close to 0.

But randomness = exploration: even weak blogs get rare high draws.

ğŸ“ Boosts added:

freshBoost = 1.1 â†’ if blog <72h old, small push.

jitter = Â±1% â†’ break ties, add randomness.

ğŸ“ Sorting:

Blogs ranked by score.

Top N (limit=4 by default, can be 2/12 via query) returned.

â³ 5. Decay Mechanism

In utils/decay.js:
Every day at 03:15 AM, run:

$mul: {
  alpha: 0.97,
  beta: 0.97,
  impressions: 0.97,
  clicks: 0.97,
  engaged_count: 0.97
}


ğŸ“ Effect:

Old stats fade by 3% daily.

Recent behavior dominates.

Prevents old â€œsuperstarsâ€ from staying top forever.

ğŸ•“ 6. Trending API (/trending)

Steps inside getTrending:

Time filter:

Default = last 60 days (windowDays).

Override with ?all=1 to bypass.

Fetch posts from Blog collection.

Match stats from BlogStat.

Compute score for each:

Î¸ (random from Beta).

Apply freshBoost if <72h old.

Apply small jitter.

Sort descending by score.

Pick unique categories first (diversity).

Fill remaining slots.

Ensure 1 fresh blog if possible.

Return as items.

ğŸ” 7. Walkthrough Example

Suppose you have 3 blogs:

Blog A (old, strong)

Î±=80, Î²=20 â†’ CTR â‰ˆ 80%.

Î¸ usually â‰ˆ 0.8.

Blog B (new, untested)

Î±=2, Î²=3 â†’ CTR â‰ˆ 40%, but uncertain.

Î¸ sometimes 0.7, sometimes 0.2.

Gets freshBoost (10%).

Blog C (bad)

Î±=1, Î²=50 â†’ CTR â‰ˆ 2%.

Î¸ rarely >0.1.

ğŸ‘‰ Trending picks:

Usually Blog A.

Sometimes Blog B wins lottery â†’ exposure.

Blog C almost never, but tiny chance.

ğŸ“Š 8. What Happens if User Refreshes?

Impression API fires every time â†’ impressions++.

Click API fires if clicked from list â†’ clicks++.

Read-End API fires on exit â†’ Î±++ or Î²++.

If refresh = bot-like (<5s, no scroll) â†’ ignored.

Effect:

Repeated refreshes inflate impressions.

If no engagement, beta rises â†’ blog trends less.

If engaged reads, alpha rises â†’ blog trends more.

ğŸ§¾ 9. Debugging Checklist

Check BlogStat:

db.blogstats.find({postId:ObjectId("...")}).pretty()


Î±/Î²: trending quality score.

impressions/clicks: exposure counts.

engaged_count: successes.

lastUpdated: freshness.

Force blog trending:

db.blogstats.updateOne(
  {postId:ObjectId("...")},
  {$set:{alpha:100, beta:1}}
)


Guarantees high Î¸ draws.

Simulate decay:

Check if Î±/Î² are shrinking daily.

ğŸ” 10. Edge Cases

No blogs in DB â†’ trending returns [].

Less blogs than limit â†’ trending returns all available.

New blogs with no reads â†’ Î±=1.5, Î²=1 (priors).

Bot-like readers (<5s + <15% scroll) â†’ ignored.

Blogs older than 60 days â†’ excluded unless ?all=1.

ğŸ¯ 11. Why This Is RL in Action

Agent = trending API.

Actions = which blogs to display.

Environment = users.

Reward = engagement (alpha increments).

Policy = Thompson Sampling with priors + decay.

Exploration = randomness in Î¸.

Exploitation = blogs with high Î± trending more.

ğŸ‘‰ Over time, the system learns automatically which blogs are good and keeps adapting.

âœ… In One Line:
Your system is a self-updating bandit where every user event teaches the algorithm â€” impressions track exposure, clicks show interest, read-end decides quality, decay forgets old data, and Thompson Sampling balances randomness with confidence to choose which blogs trend.

ğŸ”¥ Now you can:

Debug by checking Î±/Î².

Manually push/pull a blog into trending.

Adjust exploration by changing priors or decay.

Control time window via windowDays.